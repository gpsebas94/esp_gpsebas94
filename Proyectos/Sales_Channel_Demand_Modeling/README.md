# üìä Sales Channel Demand Modeling - Colombia
En un entorno de ventas multicanal, comprender y predecir la demanda espec√≠fica de cada canal es fundamental para optimizar inventarios, asignar recursos y dise√±ar estrategias de marketing efectivas. Este proyecto realizado para **Virgin Mobile Latinoam√©rica** re√∫ne los an√°lisis de datos hist√≥ricos y los modelos predictivos aplicados a los diferentes canales de venta ‚ÄîTelesales, Digital, Direct Sales Force, Distribuidores Tradicionales, Kioskos, Own Stores, Punto Partner y Retail‚Äî de **Colombia** para ofrecer una visi√≥n consolidada de su comportamiento. Cada canal de venta recorre desde la extracci√≥n y limpieza de datos hasta el entrenamiento, evaluaci√≥n y comparaci√≥n de m√∫ltiples algoritmos de regresi√≥n.

---

## üéØ Objetivo del Proyecto

- **Evaluar** caracter√≠sticas y comportamiento de la demanda/ventas en cada canal.
- **Comparar** algoritmos de regresi√≥n (Lineal, √Årbol de Decisi√≥n, Random Forest, SVR, Pipelines con polinomios).
- **Identificar** factores m√°s influyentes mediante correlaciones y PCA.
- **Recomendar** el modelo m√°s robusto por canal y sugerir mejoras de feature engineering.

---

## üîç M√©todos de Modelado
A continuaci√≥n se presentan las principales t√©cnicas utilizadas:

### Regresi√≥n Lineal (Ordinary Least Squares - OLS)

- Modelo lineal que asume una relaci√≥n lineal entre las variables independientes (features) y la variable dependiente (target).
- Minimiza la suma de los errores al cuadrado (MSE) para ajustar los coeficientes.
- Adecuado cuando la relaci√≥n entre variables es aproximadamente lineal.

### √Årbol de Decisi√≥n (Decision Tree Regressor)

- Modelo no param√©trico que segmenta el espacio de features en regiones homog√©neas mediante divisiones binarias.
- Construye un √°rbol donde cada nodo interno corresponde a una condici√≥n sobre un feature.
- F√°cil de interpretar, pero susceptible a sobreajuste si no se controla la profundidad.

### Random Forest Regressor

- Ensamble de varios √°rboles de decisi√≥n entrenados con muestreo aleatorio (bagging) y selecci√≥n aleatoria de features.
- Promedia las predicciones de cada √°rbol, reduciendo varianza y sobreajuste.
- Robusto y con buen rendimiento en datos con relaciones no lineales y ruido.

### Support Vector Regressor (SVR)

- Extensi√≥n de SVM para regresi√≥n, que busca una funci√≥n que se ajuste a los datos con un margen de tolerancia (epsilon-insensitive loss).
- Puede usar diferentes kernels (lineal, polin√≥mico, RBF) para capturar relaciones no lineales.
- Eficiente en espacios de alta dimensi√≥n, pero puede ser costoso computacionalmente en grandes conjuntos de datos.

### PCA (An√°lisis de Componentes Principales)

- T√©cnica de reducci√≥n de dimensionalidad que transforma variables correlacionadas en componentes ortogonales no correlacionados.
- Ordena las componentes seg√∫n la varianza explicada y permite seleccionar las m√°s relevantes.
- Utilizado previo al modelado para reducir ruido y redundancia, mejorando eficiencia.

---

## üß™ Metodolog√≠a
El proceso de an√°lisis y modelado en este proyecto sigue una serie de pasos estandarizados para garantizar consistencia y reproducibilidad:

### Extracci√≥n de Datos
- Conexi√≥n a la base de datos mediante psycopg2 para extraer las tablas relevantes de ventas e indicadores.
- Carga de datos en dataframes de pandas.

### Limpieza y Transformaci√≥n
- Identificaci√≥n y tratamiento de valores faltantes (imputaci√≥n o eliminaci√≥n seg√∫n caso).
- Conversi√≥n de tipos (fechas, categ√≥ricas) y creaci√≥n de variables de tiempo (mes, trimestre).
- Filtrado de outliers mediante an√°lisis de percentiles y boxplots.

### An√°lisis Exploratorio (EDA)
- Visualizaci√≥n de distribuciones (histogramas, boxplots).
- C√°lculo de correlaciones y prueba de hip√≥tesis (Pearson) para identificar relaciones lineales.
- Aplicaci√≥n de PCA para entender la estructura de las variables y reducir dimensionalidad.

### Feature Engineering
- Escalado de variables num√©ricas con StandardScaler.
- Generaci√≥n de t√©rminos polin√≥micos para capturar no linealidades.
- Codificaci√≥n de variables categ√≥ricas seg√∫n necesidad.

### Modelado Predictivo
- Definici√≥n de un conjunto de algoritmos base (OLS, √Årbol de Decisi√≥n, Random Forest, SVR, Pipeline polin√≥mico).
- Divisi√≥n de datos en entrenamiento y prueba (train/test split).
- Ajuste de hiperpar√°metros b√°sicos y validaci√≥n cruzada para evaluar estabilidad.

### Evaluaci√≥n de Modelos
- C√°lculo de m√©tricas: RMSE, MAE, R¬≤ y varianza explicada.
- Comparaci√≥n de resultados en tablas y gr√°ficos de dispersi√≥n predicci√≥n vs. real.

### Documentaci√≥n de Resultados
- Registro de m√©tricas y rankings de modelos en un dataframe consolidado.
- Visualizaci√≥n de importancias de features y componentes principales.

---

## üìÅ Estructura del repositorio
```
Sales_Channel_Demand_Modeling/
‚îú‚îÄ‚îÄ notebooks/               # Carpeta con los nueve an√°lisis por canal
‚îÇ   ‚îú‚îÄ‚îÄ 01_general.ipynb     # An√°lisis combinado y preprocesamiento global
‚îÇ   ‚îú‚îÄ‚îÄ 02_telesales.ipynb   # Canal Telesales
‚îÇ   ‚îú‚îÄ‚îÄ 03_digital.ipynb     # Canal Digital
‚îÇ   ‚îú‚îÄ‚îÄ 04_direct_sales_force.ipynb  # Canal Direct Sales Force
‚îÇ   ‚îú‚îÄ‚îÄ 05_distribuidores_tradicionales.ipynb  # Canal Distribuidores Tradicionales
‚îÇ   ‚îú‚îÄ‚îÄ 06_kioskos.ipynb     # Canal Kioskos
‚îÇ   ‚îú‚îÄ‚îÄ 07_own_stores.ipynb  # Canal Own Stores
‚îÇ   ‚îú‚îÄ‚îÄ 08_punto_partner.ipynb  # Canal Punto Partner
‚îÇ   ‚îî‚îÄ‚îÄ 09_retail.ipynb      # Canal Retail
‚îú‚îÄ‚îÄ .gitignore               # Ignora checkpoints y archivos temporales
‚îî‚îÄ‚îÄ README.md                # Documentaci√≥n (este archivo)
```
### Descripci√≥n de los Notebooks
| Notebook                             | Descripci√≥n                                                                                          |
|--------------------------------------|------------------------------------------------------------------------------------------------------|
| [`01_general.ipynb`](notebooks/01_general.ipynb)                   | Extracci√≥n y limpieza global de datos, an√°lisis exploratorio conjunto, pipeline de preprocesamiento com√∫n. |
| [`02_telesales.ipynb`](notebooks/02_telesales.ipynb)                 | EDA espec√≠fico, comparativa de modelos, m√©tricas (RMSE, MAE, R¬≤).                                     |
| [`03_digital.ipynb`](notebooks/03_digital.ipynb)                   | An√°lisis de comportamientos online, transformaciones polin√≥micas, PCA en features digitales.         |
| [`04_direct_sales_force.ipynb`](notebooks/04_direct_sales_force.ipynb)        | Datos de fuerza de ventas directa, tuning de hiperpar√°metros, validaci√≥n cruzada.                    |
| [`05_distribuidores_tradicionales.ipynb`](notebooks/05_distribuidores_tradicionales.ipynb) | Segmentaci√≥n por tipo de distribuidor, correlaciones, boxplots, rendimiento de modelos est√°ndar.     |
| [`06_kioskos.ipynb`](notebooks/06_kioskos.ipynb)                   | Variables geogr√°ficas y de punto, selecci√≥n de features relevantes, comparaci√≥n de Random Forest vs OLS. |
| [`07_own_stores.ipynb`](notebooks/07_own_stores.ipynb)                | Datos de tiendas propias, an√°lisis estacional, modelos de regresi√≥n lineal avanzados.                |
| [`08_punto_partner.ipynb`](notebooks/08_punto_partner.ipynb)             | Comportamiento de partners, evaluaci√≥n con SVR y √°rboles, an√°lisis de errores.                       |
| [`09_retail.ipynb`](notebooks/09_retail.ipynb)                    | Visi√≥n general de retail, pipeline completo (EDA, PCA, modelado), matriz de comparaci√≥n de desempe√±o. |

---

## üìå Resultados Destacados

### Rendimiento de Modelos
- Random Forest obtuvo los mejores valores de RMSE y R¬≤ en la mayor√≠a de canales.
- Canales lineales como Telesales muestran R¬≤ > 0.75 con OLS.
- Para Digital y Kioskos, pipelines polin√≥micos y SVR redujeron el error en 10‚Äì15%.

### Importance de Features
- Volumen hist√≥rico y variables de estacionalidad (mes, trimestre) son consistently top-features.
- Indicadores geogr√°ficos destacan en Own Stores y Kioskos.

### Reducci√≥n de Dimensionalidad
- PCA condens√≥ variables correlacionadas manteniendo >95% de varianza explicada.
- Se redujo un 30% de features, agilizando entrenamientos.

### Recomendaciones
- Automatizar b√∫squeda de hiperpar√°metros con GridSearchCV o RandomizedSearchCV.
- Explorar ensamblados como XGBoost o LightGBM para canales complejos.
- Modificar notebooks a scripts modulares (src/) para facilitar despliegue.

---

## ‚ö†Ô∏è Nota Legal
*Los datos y visualizaciones presentados en este proyecto est√°n destinados √∫nicamente a fines acad√©micos y demostrativos. Toda la informaci√≥n confidencial ha sido procesada para cumplir con est√°ndares de privacidad y √©tica profesional.*

---

## üë§ Autor
**Sebasti√°n Gonz√°lez**  
Data Scientist 

> Proyecto desarrollado como parte del equipo de Data de Virgin Mobile Latinoam√©rica.
















